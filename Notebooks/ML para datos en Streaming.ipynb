{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2bcbb5a-351f-4c4c-84a4-3d9af96ea146",
     "showTitle": true,
     "title": "Proyecto: Procesamiento de datos a gran escala - Spark"
    }
   },
   "source": [
    "\n",
    "Las cinco fases que se realizarán en este proyecto forman un flujo de trabajo completo de ciencia de datos aplicado a un contexto de streaming de datos utilizando PySpark, desde la preparación de datos hasta la evaluación del modelo en tiempo real. El objetivo principal de este flujo de trabajo es implementar y evaluar un modelo de Machine Learning (ML), específicamente un modelo de regresión logística, para clasificar entradas de datos en streaming en tiempo real. Esto es particularmente útil en aplicaciones donde las decisiones o predicciones deben actualizarse continuamente a medida que llegan nuevos datos, como puede ser el análisis de sentimientos de reseñas de clientes o la detección de fraude en transacciones financieras.\n",
    "\n",
    "### Objetivo General\n",
    "\n",
    "El objetivo es demostrar cómo se puede preparar, implementar, y evaluar un modelo de ML para datos en streaming utilizando las capacidades de procesamiento en tiempo real de Apache Spark y su extensión PySpark. Esto incluye la preparación de datos, el entrenamiento y la evaluación del modelo, y la implementación del modelo para hacer predicciones en tiempo real sobre datos de streaming.\n",
    "\n",
    "### Descripción de lo que se hizo en cada fase:\n",
    "\n",
    "1. **Fase 1: Preparación del Modelo de ML de Regresión Logística**\n",
    "   - Se preparó y entrenó un modelo de regresión logística usando un conjunto de datos estático para predecir la satisfacción del cliente basada en varias características relacionadas con el servicio de aerolíneas. Este modelo se construyó dentro de un pipeline de ML que incluye la preparación de datos como la indexación de variables categóricas y ensamblaje de características.\n",
    "\n",
    "2. **Fase 2: Preparación de los Datos**\n",
    "   - Se dividió un archivo de datos estático en 20 partes iguales para simular un flujo de datos en streaming. Estas partes se almacenaron en un directorio específico que luego se usaría como fuente de datos en streaming.\n",
    "\n",
    "3. **Fase 3: Creación de la Fuente de Streaming**\n",
    "   - Se configuró una fuente de datos en streaming leyendo los datos divididos desde el directorio especificado. Se aplicó el modelo de ML preparado en la Fase 1 a estos datos en streaming, transformando y prediciendo en tiempo real.\n",
    "\n",
    "4. **Fase 4: Implementación de una Consulta Adicional**\n",
    "   - Se creó una consulta adicional sobre el stream resultante para almacenar las predicciones en memoria, lo que permite realizar consultas SQL sobre estos datos en tiempo real para análisis adicionales o para evaluar el rendimiento del modelo.\n",
    "\n",
    "5. **Fase 5: Evaluación del Modelo en Streaming**\n",
    "   - Se utilizó un `MulticlassClassificationEvaluator` para evaluar la precisión del modelo en tiempo real. Se generó un DataFrame a partir de la consulta almacenada en memoria para calcular y imprimir la métrica de precisión del modelo en clasificar correctamente las entradas de datos en streaming.\n",
    "\n",
    "Este flujo de trabajo demuestra el poder de Spark y PySpark para manejar y procesar grandes volúmenes de datos en tiempo real, aplicando modelos de ML complejos y evaluando su rendimiento continuamente a medida que llegan nuevos datos. Es un enfoque valioso en entornos dinámicos donde el contexto y los datos cambian rápidamente, permitiendo a las organizaciones adaptarse y responder de manera más efectiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce47c87b-0e43-47f0-bef7-b1c6577ecf2f",
     "showTitle": true,
     "title": "Fase 1: Preparación del modelo de ML de Regresión Logística."
    }
   },
   "source": [
    "\n",
    "A partir del dataset encuesta_aerolinea.csv con resultados de una encuesta de una aerolínea, generad un modelo de Regresión Logística que permita clasificar la satisfacción del cliente entre las dos posibles alternativas que se indican en la columna (satisfaction_binary) del dataset: 1 para “satisfied” o 0 para “neutral or dissatisfied”. \n",
    "\n",
    "Se deben extraer las siguientes columnas para la generación del modelo: Gender, Age, Inflight wifi service,  Departure/Arrival time convenient, Ease of Online booking, Gate location, Food and drink, Online boarding, Seat comfort, Inflight entertainment, On-board service, Leg room service, Baggage handling, Check service, Inflight service, Cleanliness, satisfaction y satisfaction_binary.\n",
    "\n",
    "Como método de preparación del DataFrame, se elige eliminar todas las observaciones que contengan NaN, utilizando el método na.drop() de la siguiente manera: <mi_dataframe>.na.drop()\n",
    "\n",
    "La columna “satisfaction_binary” contiene la representación binaria 1 o 0 de las categorías de la columna “satisfaction”. La columna “satisfaction_binary” debe pasarse como el parámetro de labelCol al crear el objeto LogisticRegression.\n",
    "\n",
    "Las columnas categóricas (Gender) deben convertirse a una representación vectorial utilizando StringIndexer() y OneHotEncoder().\n",
    "\n",
    "**Los pasos para la implementación del modelo puede reducirse a los siguientes:**\n",
    "\n",
    "1. Extracción de las columnas requeridas en un nuevo DataFrame.\n",
    "2. Limpiar el Dataframe eliminando los NaN.\n",
    "3. Convertir columnas categóricas utilizando StringIndexer y OneHotEncoder.\n",
    "4. Generar el vector con las features para el entrenamiento del modelo con VectorAssembler()\n",
    "5. Construir el objeto LogisticRegression pasando los parámetros para featuresCol y labelCol.\n",
    "6. Construir el objeto Pipeline con los diferentes pasos de transformación.\n",
    "7. Separa el conjunto de datos en conjuntos de entrenamiento y evaluación.\n",
    "8. Entrenamos el modelo con el método fit() del Pipeline.\n",
    "9. Construimos el objeto BinaryClassificationEvaluator().\n",
    "\n",
    "10\\. Evaluar la precisión (accuracy) del modelo.\n",
    "\n",
    "11\\. Utilizar la libreria handyspark para obtener el gráfico de ROC (opcional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bc93ad4-2b42-4f60-a117-b86220ce8daa",
     "showTitle": true,
     "title": "Listar los archivos en el DBFS"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/FileStore/tables/encuesta_aerolinea-1.csv</td><td>encuesta_aerolinea-1.csv</td><td>11986211</td><td>1706643440000</td></tr><tr><td>dbfs:/FileStore/tables/encuesta_aerolinea.csv</td><td>encuesta_aerolinea.csv</td><td>11986211</td><td>1706643304000</td></tr><tr><td>dbfs:/FileStore/tables/encuesta_aerolinea_simplificado-1.csv</td><td>encuesta_aerolinea_simplificado-1.csv</td><td>11986211</td><td>1705509312000</td></tr><tr><td>dbfs:/FileStore/tables/encuesta_aerolinea_simplificado.csv</td><td>encuesta_aerolinea_simplificado.csv</td><td>11986211</td><td>1705509276000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/FileStore/tables/encuesta_aerolinea-1.csv",
         "encuesta_aerolinea-1.csv",
         11986211,
         1706643440000
        ],
        [
         "dbfs:/FileStore/tables/encuesta_aerolinea.csv",
         "encuesta_aerolinea.csv",
         11986211,
         1706643304000
        ],
        [
         "dbfs:/FileStore/tables/encuesta_aerolinea_simplificado-1.csv",
         "encuesta_aerolinea_simplificado-1.csv",
         11986211,
         1705509312000
        ],
        [
         "dbfs:/FileStore/tables/encuesta_aerolinea_simplificado.csv",
         "encuesta_aerolinea_simplificado.csv",
         11986211,
         1705509276000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs\n",
    "ls dbfs:/FileStore/tables/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50fa870c-1f4c-4972-be12-3089df1f862a",
     "showTitle": true,
     "title": "Crear el RDD inicial a partir del dataset y mostrar las primeras observaciones"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>_c0</th><th>id</th><th>Gender</th><th>Customer Type</th><th>Age</th><th>Type of Travel</th><th>Class</th><th>Flight Distance</th><th>Inflight wifi service</th><th>Departure/Arrival time convenient</th><th>Ease of Online booking</th><th>Gate location</th><th>Food and drink</th><th>Online boarding</th><th>Seat comfort</th><th>Inflight entertainment</th><th>On-board service</th><th>Leg room service</th><th>Baggage handling</th><th>Checkin service</th><th>Inflight service</th><th>Cleanliness</th><th>Departure Delay in Minutes</th><th>Arrival Delay in Minutes</th><th>satisfaction</th></tr></thead><tbody><tr><td>0</td><td>70172</td><td>Male</td><td>Loyal Customer</td><td>13</td><td>Personal Travel</td><td>Eco Plus</td><td>460</td><td>3</td><td>4</td><td>3</td><td>1</td><td>5</td><td>3</td><td>5</td><td>5</td><td>4</td><td>3</td><td>4</td><td>4</td><td>5</td><td>5</td><td>25</td><td>18</td><td>neutral or dissatisfied</td></tr><tr><td>1</td><td>5047</td><td>Male</td><td>disloyal Customer</td><td>25</td><td>Business travel</td><td>Business</td><td>235</td><td>3</td><td>2</td><td>3</td><td>3</td><td>1</td><td>3</td><td>1</td><td>1</td><td>1</td><td>5</td><td>3</td><td>1</td><td>4</td><td>1</td><td>1</td><td>6</td><td>neutral or dissatisfied</td></tr><tr><td>2</td><td>110028</td><td>Female</td><td>Loyal Customer</td><td>26</td><td>Business travel</td><td>Business</td><td>1142</td><td>2</td><td>2</td><td>2</td><td>2</td><td>5</td><td>5</td><td>5</td><td>5</td><td>4</td><td>3</td><td>4</td><td>4</td><td>4</td><td>5</td><td>0</td><td>0</td><td>satisfied</td></tr><tr><td>3</td><td>24026</td><td>Female</td><td>Loyal Customer</td><td>25</td><td>Business travel</td><td>Business</td><td>562</td><td>2</td><td>5</td><td>5</td><td>5</td><td>2</td><td>2</td><td>2</td><td>2</td><td>2</td><td>5</td><td>3</td><td>1</td><td>4</td><td>2</td><td>11</td><td>9</td><td>neutral or dissatisfied</td></tr><tr><td>4</td><td>119299</td><td>Male</td><td>Loyal Customer</td><td>61</td><td>Business travel</td><td>Business</td><td>214</td><td>3</td><td>3</td><td>3</td><td>3</td><td>4</td><td>5</td><td>5</td><td>3</td><td>3</td><td>4</td><td>4</td><td>3</td><td>3</td><td>3</td><td>0</td><td>0</td><td>satisfied</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0,
         70172,
         "Male",
         "Loyal Customer",
         13,
         "Personal Travel",
         "Eco Plus",
         460,
         3,
         4,
         3,
         1,
         5,
         3,
         5,
         5,
         4,
         3,
         4,
         4,
         5,
         5,
         25,
         18,
         "neutral or dissatisfied"
        ],
        [
         1,
         5047,
         "Male",
         "disloyal Customer",
         25,
         "Business travel",
         "Business",
         235,
         3,
         2,
         3,
         3,
         1,
         3,
         1,
         1,
         1,
         5,
         3,
         1,
         4,
         1,
         1,
         6,
         "neutral or dissatisfied"
        ],
        [
         2,
         110028,
         "Female",
         "Loyal Customer",
         26,
         "Business travel",
         "Business",
         1142,
         2,
         2,
         2,
         2,
         5,
         5,
         5,
         5,
         4,
         3,
         4,
         4,
         4,
         5,
         0,
         0,
         "satisfied"
        ],
        [
         3,
         24026,
         "Female",
         "Loyal Customer",
         25,
         "Business travel",
         "Business",
         562,
         2,
         5,
         5,
         5,
         2,
         2,
         2,
         2,
         2,
         5,
         3,
         1,
         4,
         2,
         11,
         9,
         "neutral or dissatisfied"
        ],
        [
         4,
         119299,
         "Male",
         "Loyal Customer",
         61,
         "Business travel",
         "Business",
         214,
         3,
         3,
         3,
         3,
         4,
         5,
         5,
         3,
         3,
         4,
         4,
         3,
         3,
         3,
         0,
         0,
         "satisfied"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "_c0",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Customer Type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Age",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Type of Travel",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Class",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Flight Distance",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Inflight wifi service",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Departure/Arrival time convenient",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Ease of Online booking",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Gate location",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Food and drink",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Online boarding",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Seat comfort",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Inflight entertainment",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "On-board service",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Leg room service",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Baggage handling",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Checkin service",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Inflight service",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Cleanliness",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Departure Delay in Minutes",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Arrival Delay in Minutes",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "satisfaction",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lines = sc.textFile('dbfs:/FileStore/tables/encuesta_aerolinea.csv')\n",
    "df_preview = spark.read.format(\"csv\").option(\"inferSchema\",\"true\").option(\"header\",\"true\").load(\"dbfs:/FileStore/tables/encuesta_aerolinea.csv\")\n",
    "df_limited = df_preview.limit(5)  # Limita a 5 registros\n",
    "df_limited.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd9919d3-2af4-46be-ad02-df33420d9ee2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, TimestampType, IntegerType\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9aa519f-c41e-42a6-b945-588a9d52bf07",
     "showTitle": true,
     "title": "Crear el schema para el DataFrame"
    }
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"C0\", IntegerType(), True),\n",
    "    StructField(\"ID\", IntegerType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"customer_type\", StringType(), True),\n",
    "    StructField(\"age\", FloatType(), True),\n",
    "    StructField(\"type_of_travel\", StringType(), True),\n",
    "    StructField(\"class\", StringType(), True),\n",
    "    StructField(\"flight_distance\", FloatType(), True),\n",
    "    StructField(\"wifi\", FloatType(), True),\n",
    "    StructField(\"time_convenient\", FloatType(), True),\n",
    "    StructField(\"booking\", FloatType(), True),\n",
    "    StructField(\"gate\", FloatType(), True),\n",
    "    StructField(\"food\", FloatType(), True),\n",
    "    StructField(\"boarding\", FloatType(), True),\n",
    "    StructField(\"comfort\", FloatType(), True),\n",
    "    StructField(\"entertainment\", FloatType(), True),\n",
    "    StructField(\"on_board_service\", FloatType(), True),\n",
    "    StructField(\"room_service\", FloatType(), True),\n",
    "    StructField(\"handling\", FloatType(), True),\n",
    "    StructField(\"checking\", FloatType(), True),\n",
    "    StructField(\"inflight\", FloatType(), True),\n",
    "    StructField(\"cleanliness\", FloatType(), True),\n",
    "    StructField(\"departures_delay\", FloatType(), True),\n",
    "    StructField(\"arrivals_delay\", FloatType(), True),\n",
    "    StructField(\"satisfaction\", StringType(), True), \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c0c5d1a-9e1d-4e57-b4d5-79213ff0556b",
     "showTitle": true,
     "title": "Crear el DataFrame e imprimir el esquema"
    }
   },
   "outputs": [],
   "source": [
    "df_raw = spark.read.format(\"csv\").option(\"header\", True).schema(schema).load('dbfs:/FileStore/tables/encuesta_aerolinea.csv')\n",
    "df = df_raw.na.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11d67059-f453-4c22-9b2d-b0977c83e51f",
     "showTitle": true,
     "title": "MLlib"
    }
   },
   "source": [
    "\n",
    "MLlib es la biblioteca de aprendizaje automático (machine learning) de Apache Spark. Está diseñada para simplificar la construcción de aplicaciones de aprendizaje automático a gran escala, integrándose de manera fluida con el resto del ecosistema de Spark. \n",
    "\n",
    "MLlib proporciona una amplia variedad de algoritmos y utilidades comunes de aprendizaje automático, incluyendo clasificación, regresión, clustering, filtrado colaborativo (como sistemas de recomendación), reducción de dimensionalidad, y selección de modelos. Aprovecha la distribución de datos y el procesamiento en paralelo de Spark, lo que la hace adecuada para manejar grandes volúmenes de datos de manera eficiente.\n",
    "\n",
    "Aunque MLlib está escrita en Scala, es accesible desde otros lenguajes de programación soportados por Spark, como Python (a través de PySpark) y Java.\n",
    "\n",
    "Por lo tanto, MLlib es una biblioteca robusta y versátil para realizar aprendizaje automático en plataformas distribuidas, aprovechando la potencia y escala de Apache Spark. Es especialmente útil para aplicaciones que requieren manejar grandes conjuntos de datos y realizar operaciones de aprendizaje automático complejas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78e9427b-1051-4355-9ecd-4e01cd0897ce",
     "showTitle": true,
     "title": "1. Extracción de las Columnas Requeridas"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Seleccionar las columnas necesarias\n",
    "selected_columns = [\n",
    "    \"gender\", \"age\", \"wifi\", \"time_convenient\", \"booking\",\n",
    "    \"gate\", \"food\", \"boarding\", \"comfort\", \"entertainment\",\n",
    "    \"on_board_service\", \"room_service\", \"handling\", \"checking\",\n",
    "    \"inflight\", \"cleanliness\", \"satisfaction\"\n",
    "]\n",
    "\n",
    "df_selected = df.select(selected_columns)\n",
    "\n",
    "# Convertir la columna 'satisfaction' en binaria\n",
    "df_selected = df_selected.withColumn(\n",
    "    \"satisfaction_binary\", \n",
    "    when(col(\"satisfaction\") == \"satisfied\", 1).otherwise(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcc04211-0730-4dd3-a807-e6da2336927e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Se hace una copia del df_selected para usarlo a partir de la Fase 2\n",
    "df_proyecto = df_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c26d1419-4cb3-42b4-99ab-3a3726d10485",
     "showTitle": true,
     "title": "2.  Transformación de Características"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Indexar y codificar las columnas categóricas\n",
    "gender_indexer = StringIndexer(inputCol=\"gender\", outputCol=\"genderIndex\")\n",
    "gender_encoder = OneHotEncoder(inputCol=\"genderIndex\", outputCol=\"genderVec\")\n",
    "\n",
    "# Asssembler de todas las características en un vector\n",
    "assembler_inputs = [\"genderVec\"] + selected_columns[1:-2]  # excluyendo la columna 'satisfaction' y 'satisfaction_binary'\n",
    "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a5c1a6e-12d1-44d1-a2c0-c58adcd18962",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "En esta parte, se trabaja con la transformación de características, específicamente indexando y codificando las variables categóricas y combinando todas las características relevantes en un solo vector.\n",
    "\n",
    "1. **Importar las funciones necesarias de PySpark ML**:\n",
    "\n",
    "   - `StringIndexer`, `OneHotEncoder`, y `VectorAssembler` son transformadores de PySpark ML que ayudan a convertir datos en formatos adecuados para modelos de aprendizaje automático.\n",
    "   - `Pipeline` es una forma de encadenar múltiples transformaciones y estimadores, lo que facilita la construcción y gestión de flujos de trabajo de aprendizaje automático.\n",
    "\n",
    "2. **Indexar y codificar las columnas categóricas**:\n",
    "\n",
    "   - `StringIndexer`: Convierte la columna categórica 'gender' en índices numéricos. Esto es necesario porque muchos algoritmos de aprendizaje automático prefieren trabajar con números en lugar de texto.\n",
    "   - `OneHotEncoder`: Transforma los índices numéricos generados por `StringIndexer` en un formato de codificación one-hot. En la codificación one-hot, cada categoría única en la columna se representa como un vector binario.\n",
    "\n",
    "3. **Assembler de todas las características en un vector**:\n",
    "\n",
    "   - Aquí, se crea una lista `assembler_inputs` que contiene el nombre de la columna codificada ('genderVec') y todas las otras columnas seleccionadas, excepto 'satisfaction' y 'satisfaction_binary'.\n",
    "   - `VectorAssembler` se utiliza para combinar todas estas columnas en una única columna de características llamada 'features'. Esto es importante porque los modelos de aprendizaje automático en PySpark, como la regresión logística, esperan que los datos de entrada estén en un único vector de características.\n",
    "\n",
    "Estas operaciones están preparando los datos para ser utilizados en un modelo de aprendizaje automático, asegurando que todas las variables estén en el formato adecuado y combinadas en una estructura que el modelo puede procesar eficientemente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75758d70-b72c-4578-8733-6e755fa52bc5",
     "showTitle": true,
     "title": "3. Construcción del Modelo"
    }
   },
   "outputs": [],
   "source": [
    "#Configura y agrega la regresión logística al pipeline.\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Configurar la regresión logística\n",
    "lr = LogisticRegression(labelCol=\"satisfaction_binary\", featuresCol=\"features\")\n",
    "\n",
    "\n",
    "# Creación del pipeline\n",
    "preprocessing_stages = [gender_indexer, gender_encoder, assembler,lr]\n",
    "pipeline = Pipeline(stages=preprocessing_stages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61971586-75f9-40bd-9d8e-1818ed4ed6c2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "Aquí, se configura el estimador de regresión logística y se integra junto con las etapas de preprocesamiento previas en un solo pipeline. Veamos cada paso en detalle:\n",
    "\n",
    "1. **Importar LogisticRegression de PySpark ML**:\n",
    "   `LogisticRegression` es la clase de PySpark ML que proporciona la implementación del algoritmo de regresión logística para la clasificación binaria.\n",
    "\n",
    "2. **Configurar la regresión logística**:\n",
    "\n",
    "   Aquí, se crea una instancia del modelo de regresión logística (`lr`). \n",
    "   - `labelCol=\"satisfaction_binary\"` indica que la columna 'satisfaction_binary' será utilizada como la etiqueta (o variable dependiente) para el modelo. Esta es la columna que se transformó anteriormente a formato binario.\n",
    "   - `featuresCol=\"features\"` especifica que la columna 'features' contiene las características (o variables independientes) que el modelo usará para hacer predicciones. Esta columna fue generada por el `VectorAssembler` y contiene todas las características relevantes en un formato vectorial.\n",
    "\n",
    "3. **Creación del pipeline**:\n",
    "   - Aquí, se crea una lista `preprocessing_stages` que incluye todas las etapas de preprocesamiento (`gender_indexer`, `gender_encoder`, `assembler`) y el modelo de regresión logística (`lr`).\n",
    "   - Luego, se crea un objeto `Pipeline` con estas etapas. En PySpark, un `Pipeline` es una secuencia de transformadores y estimadores (como modelos de aprendizaje automático) que se ejecutan en un orden específico. Este enfoque facilita la gestión del flujo de trabajo, ya que permite que los datos pasen a través de todas las etapas de preprocesamiento y modelización de manera eficiente y ordenada.\n",
    "\n",
    "Este código finaliza la configuración del flujo de trabajo para el modelo de regresión logística. Una vez que el `Pipeline` está configurado, puedes entrenarlo con un conjunto de datos y luego usarlo para hacer predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50d07405-d4a9-4257-a8ee-8a82fff13ea6",
     "showTitle": true,
     "title": "4. Entrenamiento y Evaluación del Modelo"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Área bajo la curva ROC: 0.87703653846697\n"
     ]
    }
   ],
   "source": [
    "# Dividir en conjunto de entrenamiento y prueba\n",
    "train_data, test_data = df_selected.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model = pipeline.fit(train_data)\n",
    "\n",
    "# Realizar predicciones\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Evaluar el modelo\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"satisfaction_binary\", metricName=\"areaUnderROC\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "print(f\"Área bajo la curva ROC: {auc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8ea8d49-347b-4520-b4ae-d2ab8ede3304",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "Este último fragmento de código completa el flujo de trabajo del modelo de regresión logística en PySpark, abarcando la división de los datos, el entrenamiento del modelo, la realización de predicciones y la evaluación del modelo. Expliquemos cada paso:\n",
    "\n",
    "1. **Dividir en conjunto de entrenamiento y prueba**:\n",
    "\n",
    "   Aquí, se divide el DataFrame `df_selected` en dos subconjuntos: uno para entrenamiento (`train_data`) y otro para pruebas (`test_data`). La división se hace de forma que el 70% de los datos se asignan al entrenamiento y el 30% a las pruebas. El `seed` se establece para garantizar la reproducibilidad de los resultados.\n",
    "\n",
    "2. **Entrenar el modelo**:\n",
    "   ```python\n",
    "   model = pipeline.fit(train_data)\n",
    "   ```\n",
    "   Esta línea entrena el `pipeline`, que incluye todas las etapas de preprocesamiento y el modelo de regresión logística, utilizando el conjunto de datos de entrenamiento (`train_data`).\n",
    "\n",
    "3. **Realizar predicciones**:\n",
    "  \n",
    "   Una vez que el modelo está entrenado, se utiliza para hacer predicciones en el conjunto de datos de prueba (`test_data`). El resultado, `predictions`, es un DataFrame que incluye las predicciones del modelo.\n",
    "\n",
    "4. **Evaluar el modelo**:\n",
    " \n",
    "   - Aquí, se importa `BinaryClassificationEvaluator` de PySpark ML, una clase que proporciona herramientas para evaluar modelos de clasificación binaria.\n",
    "   - Se cre un evaluador `evaluator` configurado para usar la métrica \"areaUnderROC\" (área bajo la curva ROC). La curva ROC es una herramienta común para evaluar el rendimiento de los modelos de clasificación binaria.\n",
    "   - Finalmente, se utiliza el evaluador para calcular el AUC (área bajo la curva ROC) en las predicciones realizadas. Un valor más alto de AUC indica generalmente un mejor rendimiento del modelo.\n",
    "\n",
    "Este flujo de trabajo completo demuestra cómo preparar datos, configurar un modelo de regresión logística, entrenarlo y evaluarlo usando PySpark. El área bajo la curva ROC es una métrica útil para comprender el rendimiento general del modelo en términos de su capacidad para distinguir entre las clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c99cf0b-d9f9-4ebb-9740-b986d468588f",
     "showTitle": true,
     "title": "Fase 2: Preparación de los datos"
    }
   },
   "source": [
    "\n",
    "El fichero original encuesta_aerolinea.csv debe repartirse entre 20 partes iguales utilizando el método repartition() y las partes del fichero deberán guardarse en un un directorio que constituirá la fuente del stream de datos.\n",
    "\n",
    "El directorio de fuente del stream debe ser borrado completamente con cada ejecución del stream para que la simulación funcione correctamente. El directorio de origen de los datos debe ser siempre el siguiente: dbfs:/FileStore/tables/proyecto/streaming/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90b9f285-330c-45b5-a82a-421f5cb9475e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Repartir en 20 partes\n",
    "df_repartitioned = df_proyecto.repartition(20)\n",
    "\n",
    "# Borrar el directorio de destino si existe (Ajustar según el entorno de ejecución)\n",
    "dbutils.fs.rm(\"dbfs:/FileStore/tables/proyecto/streaming/\", recurse=True)\n",
    "\n",
    "# Guardar las partes en el directorio\n",
    "df_repartitioned.write.format(\"parquet\").save(\"dbfs:/FileStore/tables/proyecto/streaming/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eaa3d324-8eef-4839-9748-7b5d0bfc5e4d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "1. **Repartir DataFrame en 20 partes:** `df_proyecto.repartition(20)` redistribuye el DataFrame `df_proyecto` en 20 particiones para optimizar el procesamiento paralelo.\n",
    "\n",
    "2. **Eliminar directorio existente:** `dbutils.fs.rm(\"dbfs:/FileStore/tables/proyecto/streaming/\", recurse=True)` usa Databricks Utilities para eliminar un directorio y todo su contenido en DBFS, si ya existe, para evitar conflictos de datos.\n",
    "\n",
    "3. **Guardar DataFrame en formato Parquet:** `df_repartitioned.write.format(\"parquet\").save(\"dbfs:/FileStore/tables/proyecto/streaming/\")` guarda el DataFrame reparticionado en el sistema de archivos de Databricks (DBFS) en formato Parquet, que es eficiente para el almacenamiento y análisis de grandes volúmenes de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5403e9f6-a912-423f-8edb-b099a87bb54a",
     "showTitle": true,
     "title": "Fase 3: Creación de la fuente de streaming"
    }
   },
   "source": [
    "\n",
    "Se deberá crear la fuente de datos para el stream con el método readStream() y los parámetros requeridos para su correcta implementación.\n",
    "\n",
    "Se deberá aplicar el método transform() sobre el modelo generado pasando como parámetro el stream de fuente previamente creado y visualizar el stream de datos resultante con el  método display()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ce521ae-dde8-4c56-8b50-543155146e20",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>gender</th><th>age</th><th>wifi</th><th>time_convenient</th><th>booking</th><th>gate</th><th>food</th><th>boarding</th><th>comfort</th><th>entertainment</th><th>on_board_service</th><th>room_service</th><th>handling</th><th>checking</th><th>inflight</th><th>cleanliness</th><th>satisfaction</th><th>satisfaction_binary</th><th>genderIndex</th><th>genderVec</th><th>features</th><th>rawPrediction</th><th>probability</th><th>prediction</th></tr></thead><tbody><tr><td>Male</td><td>53.0</td><td>3.0</td><td>5.0</td><td>3.0</td><td>3.0</td><td>3.0</td><td>3.0</td><td>3.0</td><td>3.0</td><td>3.0</td><td>2.0</td><td>1.0</td><td>4.0</td><td>1.0</td><td>3.0</td><td>neutral or dissatisfied</td><td>0</td><td>1.0</td><td>Map(vectorType -> sparse, length -> 1, indices -> List(), values -> List())</td><td>Map(vectorType -> dense, length -> 15, values -> List(0.0, 53.0, 3.0, 5.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 4.0, 1.0))</td><td>Map(vectorType -> dense, length -> 2, values -> List(1.8417562805588128, -1.8417562805588128))</td><td>Map(vectorType -> dense, length -> 2, values -> List(0.86315628725477, 0.13684371274523))</td><td>0.0</td></tr><tr><td>Female</td><td>58.0</td><td>5.0</td><td>5.0</td><td>5.0</td><td>5.0</td><td>2.0</td><td>5.0</td><td>4.0</td><td>4.0</td><td>4.0</td><td>4.0</td><td>4.0</td><td>3.0</td><td>4.0</td><td>3.0</td><td>satisfied</td><td>1</td><td>0.0</td><td>Map(vectorType -> sparse, length -> 1, indices -> List(0), values -> List(1.0))</td><td>Map(vectorType -> dense, length -> 15, values -> List(1.0, 58.0, 5.0, 5.0, 5.0, 5.0, 2.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 4.0))</td><td>Map(vectorType -> dense, length -> 2, values -> List(-1.784327266256624, 1.784327266256624))</td><td>Map(vectorType -> dense, length -> 2, values -> List(0.1437696263849696, 0.8562303736150304))</td><td>1.0</td></tr><tr><td>Female</td><td>66.0</td><td>3.0</td><td>4.0</td><td>3.0</td><td>5.0</td><td>2.0</td><td>3.0</td><td>5.0</td><td>1.0</td><td>1.0</td><td>3.0</td><td>1.0</td><td>5.0</td><td>1.0</td><td>5.0</td><td>neutral or dissatisfied</td><td>0</td><td>0.0</td><td>Map(vectorType -> sparse, length -> 1, indices -> List(0), values -> List(1.0))</td><td>Map(vectorType -> dense, length -> 15, values -> List(1.0, 66.0, 3.0, 4.0, 3.0, 5.0, 2.0, 3.0, 5.0, 1.0, 1.0, 3.0, 1.0, 5.0, 1.0))</td><td>Map(vectorType -> dense, length -> 2, values -> List(1.5222076592829952, -1.5222076592829952))</td><td>Map(vectorType -> dense, length -> 2, values -> List(0.8208633396273257, 0.17913666037267428))</td><td>0.0</td></tr><tr><td>Male</td><td>39.0</td><td>5.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>5.0</td><td>5.0</td><td>5.0</td><td>5.0</td><td>4.0</td><td>5.0</td><td>5.0</td><td>5.0</td><td>5.0</td><td>5.0</td><td>satisfied</td><td>1</td><td>1.0</td><td>Map(vectorType -> sparse, length -> 1, indices -> List(), values -> List())</td><td>Map(vectorType -> dense, length -> 15, values -> List(0.0, 39.0, 5.0, 1.0, 1.0, 1.0, 5.0, 5.0, 5.0, 5.0, 4.0, 5.0, 5.0, 5.0, 5.0))</td><td>Map(vectorType -> dense, length -> 2, values -> List(-4.164917611882765, 4.164917611882765))</td><td>Map(vectorType -> dense, length -> 2, values -> List(0.015293471594832478, 0.9847065284051675))</td><td>1.0</td></tr><tr><td>Female</td><td>34.0</td><td>4.0</td><td>2.0</td><td>4.0</td><td>4.0</td><td>5.0</td><td>4.0</td><td>5.0</td><td>5.0</td><td>1.0</td><td>1.0</td><td>4.0</td><td>2.0</td><td>4.0</td><td>5.0</td><td>satisfied</td><td>1</td><td>0.0</td><td>Map(vectorType -> sparse, length -> 1, indices -> List(0), values -> List(1.0))</td><td>Map(vectorType -> dense, length -> 15, values -> List(1.0, 34.0, 4.0, 2.0, 4.0, 4.0, 5.0, 4.0, 5.0, 5.0, 1.0, 1.0, 4.0, 2.0, 4.0))</td><td>Map(vectorType -> dense, length -> 2, values -> List(0.3538350975341018, -0.3538350975341018))</td><td>Map(vectorType -> dense, length -> 2, values -> List(0.5875472701083173, 0.4124527298916827))</td><td>0.0</td></tr><tr><td>Male</td><td>48.0</td><td>4.0</td><td>4.0</td><td>4.0</td><td>4.0</td><td>5.0</td><td>5.0</td><td>4.0</td><td>4.0</td><td>4.0</td><td>4.0</td><td>4.0</td><td>5.0</td><td>4.0</td><td>3.0</td><td>satisfied</td><td>1</td><td>1.0</td><td>Map(vectorType -> sparse, length -> 1, indices -> List(), values -> List())</td><td>Map(vectorType -> dense, length -> 15, values -> List(0.0, 48.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 4.0))</td><td>Map(vectorType -> dense, length -> 2, values -> List(-2.1340192101458753, 2.1340192101458753))</td><td>Map(vectorType -> dense, length -> 2, values -> List(0.10583403797251299, 0.894165962027487))</td><td>1.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Male",
         53.0,
         3.0,
         5.0,
         3.0,
         3.0,
         3.0,
         3.0,
         3.0,
         3.0,
         3.0,
         2.0,
         1.0,
         4.0,
         1.0,
         3.0,
         "neutral or dissatisfied",
         0,
         1.0,
         {
          "indices": [],
          "length": 1,
          "values": [],
          "vectorType": "sparse"
         },
         {
          "length": 15,
          "values": [
           0.0,
           53.0,
           3.0,
           5.0,
           3.0,
           3.0,
           3.0,
           3.0,
           3.0,
           3.0,
           3.0,
           2.0,
           1.0,
           4.0,
           1.0
          ],
          "vectorType": "dense"
         },
         {
          "length": 2,
          "values": [
           1.8417562805588128,
           -1.8417562805588128
          ],
          "vectorType": "dense"
         },
         {
          "length": 2,
          "values": [
           0.86315628725477,
           0.13684371274523
          ],
          "vectorType": "dense"
         },
         0.0
        ],
        [
         "Female",
         58.0,
         5.0,
         5.0,
         5.0,
         5.0,
         2.0,
         5.0,
         4.0,
         4.0,
         4.0,
         4.0,
         4.0,
         3.0,
         4.0,
         3.0,
         "satisfied",
         1,
         0.0,
         {
          "indices": [
           0
          ],
          "length": 1,
          "values": [
           1.0
          ],
          "vectorType": "sparse"
         },
         {
          "length": 15,
          "values": [
           1.0,
           58.0,
           5.0,
           5.0,
           5.0,
           5.0,
           2.0,
           5.0,
           4.0,
           4.0,
           4.0,
           4.0,
           4.0,
           3.0,
           4.0
          ],
          "vectorType": "dense"
         },
         {
          "length": 2,
          "values": [
           -1.784327266256624,
           1.784327266256624
          ],
          "vectorType": "dense"
         },
         {
          "length": 2,
          "values": [
           0.1437696263849696,
           0.8562303736150304
          ],
          "vectorType": "dense"
         },
         1.0
        ],
        [
         "Female",
         66.0,
         3.0,
         4.0,
         3.0,
         5.0,
         2.0,
         3.0,
         5.0,
         1.0,
         1.0,
         3.0,
         1.0,
         5.0,
         1.0,
         5.0,
         "neutral or dissatisfied",
         0,
         0.0,
         {
          "indices": [
           0
          ],
          "length": 1,
          "values": [
           1.0
          ],
          "vectorType": "sparse"
         },
         {
          "length": 15,
          "values": [
           1.0,
           66.0,
           3.0,
           4.0,
           3.0,
           5.0,
           2.0,
           3.0,
           5.0,
           1.0,
           1.0,
           3.0,
           1.0,
           5.0,
           1.0
          ],
          "vectorType": "dense"
         },
         {
          "length": 2,
          "values": [
           1.5222076592829952,
           -1.5222076592829952
          ],
          "vectorType": "dense"
         },
         {
          "length": 2,
          "values": [
           0.8208633396273257,
           0.17913666037267428
          ],
          "vectorType": "dense"
         },
         0.0
        ],
        [
         "Male",
         39.0,
         5.0,
         1.0,
         1.0,
         1.0,
         5.0,
         5.0,
         5.0,
         5.0,
         4.0,
         5.0,
         5.0,
         5.0,
         5.0,
         5.0,
         "satisfied",
         1,
         1.0,
         {
          "indices": [],
          "length": 1,
          "values": [],
          "vectorType": "sparse"
         },
         {
          "length": 15,
          "values": [
           0.0,
           39.0,
           5.0,
           1.0,
           1.0,
           1.0,
           5.0,
           5.0,
           5.0,
           5.0,
           4.0,
           5.0,
           5.0,
           5.0,
           5.0
          ],
          "vectorType": "dense"
         },
         {
          "length": 2,
          "values": [
           -4.164917611882765,
           4.164917611882765
          ],
          "vectorType": "dense"
         },
         {
          "length": 2,
          "values": [
           0.015293471594832478,
           0.9847065284051675
          ],
          "vectorType": "dense"
         },
         1.0
        ],
        [
         "Female",
         34.0,
         4.0,
         2.0,
         4.0,
         4.0,
         5.0,
         4.0,
         5.0,
         5.0,
         1.0,
         1.0,
         4.0,
         2.0,
         4.0,
         5.0,
         "satisfied",
         1,
         0.0,
         {
          "indices": [
           0
          ],
          "length": 1,
          "values": [
           1.0
          ],
          "vectorType": "sparse"
         },
         {
          "length": 15,
          "values": [
           1.0,
           34.0,
           4.0,
           2.0,
           4.0,
           4.0,
           5.0,
           4.0,
           5.0,
           5.0,
           1.0,
           1.0,
           4.0,
           2.0,
           4.0
          ],
          "vectorType": "dense"
         },
         {
          "length": 2,
          "values": [
           0.3538350975341018,
           -0.3538350975341018
          ],
          "vectorType": "dense"
         },
         {
          "length": 2,
          "values": [
           0.5875472701083173,
           0.4124527298916827
          ],
          "vectorType": "dense"
         },
         0.0
        ],
        [
         "Male",
         48.0,
         4.0,
         4.0,
         4.0,
         4.0,
         5.0,
         5.0,
         4.0,
         4.0,
         4.0,
         4.0,
         4.0,
         5.0,
         4.0,
         3.0,
         "satisfied",
         1,
         1.0,
         {
          "indices": [],
          "length": 1,
          "values": [],
          "vectorType": "sparse"
         },
         {
          "length": 15,
          "values": [
           0.0,
           48.0,
           4.0,
           4.0,
           4.0,
           4.0,
           5.0,
           5.0,
           4.0,
           4.0,
           4.0,
           4.0,
           4.0,
           5.0,
           4.0
          ],
          "vectorType": "dense"
         },
         {
          "length": 2,
          "values": [
           -2.1340192101458753,
           2.1340192101458753
          ],
          "vectorType": "dense"
         },
         {
          "length": 2,
          "values": [
           0.10583403797251299,
           0.894165962027487
          ],
          "vectorType": "dense"
         },
         1.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "wifi",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "time_convenient",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "booking",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "gate",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "food",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "boarding",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "comfort",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "entertainment",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "on_board_service",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "room_service",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "handling",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "checking",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "inflight",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "cleanliness",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "satisfaction",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "satisfaction_binary",
         "type": "\"integer\""
        },
        {
         "metadata": "{\"ml_attr\":{\"vals\":[\"Female\",\"Male\"],\"type\":\"nominal\",\"name\":\"genderIndex\"}}",
         "name": "genderIndex",
         "type": "\"double\""
        },
        {
         "metadata": "{\"ml_attr\":{\"attrs\":{\"binary\":[{\"idx\":0,\"name\":\"Female\"}]},\"num_attrs\":1}}",
         "name": "genderVec",
         "type": "{\"type\":\"udt\",\"class\":\"org.apache.spark.ml.linalg.VectorUDT\",\"pyClass\":\"pyspark.ml.linalg.VectorUDT\",\"sqlType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"type\",\"type\":\"byte\",\"nullable\":false,\"metadata\":{}},{\"name\":\"size\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"indices\",\"type\":{\"type\":\"array\",\"elementType\":\"integer\",\"containsNull\":false},\"nullable\":true,\"metadata\":{}},{\"name\":\"values\",\"type\":{\"type\":\"array\",\"elementType\":\"double\",\"containsNull\":false},\"nullable\":true,\"metadata\":{}}]}}"
        },
        {
         "metadata": "{\"ml_attr\":{\"attrs\":{\"numeric\":[{\"idx\":1,\"name\":\"age\"},{\"idx\":2,\"name\":\"wifi\"},{\"idx\":3,\"name\":\"time_convenient\"},{\"idx\":4,\"name\":\"booking\"},{\"idx\":5,\"name\":\"gate\"},{\"idx\":6,\"name\":\"food\"},{\"idx\":7,\"name\":\"boarding\"},{\"idx\":8,\"name\":\"comfort\"},{\"idx\":9,\"name\":\"entertainment\"},{\"idx\":10,\"name\":\"on_board_service\"},{\"idx\":11,\"name\":\"room_service\"},{\"idx\":12,\"name\":\"handling\"},{\"idx\":13,\"name\":\"checking\"},{\"idx\":14,\"name\":\"inflight\"}],\"binary\":[{\"idx\":0,\"name\":\"genderVec_Female\"}]},\"num_attrs\":15}}",
         "name": "features",
         "type": "{\"type\":\"udt\",\"class\":\"org.apache.spark.ml.linalg.VectorUDT\",\"pyClass\":\"pyspark.ml.linalg.VectorUDT\",\"sqlType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"type\",\"type\":\"byte\",\"nullable\":false,\"metadata\":{}},{\"name\":\"size\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"indices\",\"type\":{\"type\":\"array\",\"elementType\":\"integer\",\"containsNull\":false},\"nullable\":true,\"metadata\":{}},{\"name\":\"values\",\"type\":{\"type\":\"array\",\"elementType\":\"double\",\"containsNull\":false},\"nullable\":true,\"metadata\":{}}]}}"
        },
        {
         "metadata": "{\"ml_attr\":{\"num_attrs\":2}}",
         "name": "rawPrediction",
         "type": "{\"type\":\"udt\",\"class\":\"org.apache.spark.ml.linalg.VectorUDT\",\"pyClass\":\"pyspark.ml.linalg.VectorUDT\",\"sqlType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"type\",\"type\":\"byte\",\"nullable\":false,\"metadata\":{}},{\"name\":\"size\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"indices\",\"type\":{\"type\":\"array\",\"elementType\":\"integer\",\"containsNull\":false},\"nullable\":true,\"metadata\":{}},{\"name\":\"values\",\"type\":{\"type\":\"array\",\"elementType\":\"double\",\"containsNull\":false},\"nullable\":true,\"metadata\":{}}]}}"
        },
        {
         "metadata": "{\"ml_attr\":{\"num_attrs\":2}}",
         "name": "probability",
         "type": "{\"type\":\"udt\",\"class\":\"org.apache.spark.ml.linalg.VectorUDT\",\"pyClass\":\"pyspark.ml.linalg.VectorUDT\",\"sqlType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"type\",\"type\":\"byte\",\"nullable\":false,\"metadata\":{}},{\"name\":\"size\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"indices\",\"type\":{\"type\":\"array\",\"elementType\":\"integer\",\"containsNull\":false},\"nullable\":true,\"metadata\":{}},{\"name\":\"values\",\"type\":{\"type\":\"array\",\"elementType\":\"double\",\"containsNull\":false},\"nullable\":true,\"metadata\":{}}]}}"
        },
        {
         "metadata": "{\"ml_attr\":{\"type\":\"nominal\",\"num_vals\":2}}",
         "name": "prediction",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "schema1 = StructType([\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"age\", FloatType(), True),\n",
    "    StructField(\"wifi\", FloatType(), True),\n",
    "    StructField(\"time_convenient\", FloatType(), True),\n",
    "    StructField(\"booking\", FloatType(), True),\n",
    "    StructField(\"gate\", FloatType(), True),\n",
    "    StructField(\"food\", FloatType(), True),\n",
    "    StructField(\"boarding\", FloatType(), True),\n",
    "    StructField(\"comfort\", FloatType(), True),\n",
    "    StructField(\"entertainment\", FloatType(), True),\n",
    "    StructField(\"on_board_service\", FloatType(), True),\n",
    "    StructField(\"room_service\", FloatType(), True),\n",
    "    StructField(\"handling\", FloatType(), True),\n",
    "    StructField(\"checking\", FloatType(), True),\n",
    "    StructField(\"inflight\", FloatType(), True),\n",
    "    StructField(\"cleanliness\", FloatType(), True),\n",
    "    StructField(\"satisfaction\", StringType(), True), \n",
    "    StructField(\"satisfaction_binary\", IntegerType(), True)\n",
    "\n",
    "])\n",
    "\n",
    "# Crear la fuente de datos para el stream\n",
    "streamingInputDF = (\n",
    "  spark\n",
    "    .readStream\n",
    "    .schema(schema1)  # Asegúrate de definir el esquema adecuado\n",
    "    .format(\"parquet\")\n",
    "    .load(\"dbfs:/FileStore/tables/proyecto/streaming/\")\n",
    ")\n",
    "\n",
    "# Aplicar el modelo al stream de datos\n",
    "streamingPredictions = model.transform(streamingInputDF)\n",
    "\n",
    "# Visualizar el stream de datos resultante \n",
    "display(streamingPredictions.limit(6))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f39c7cb-e21c-4398-837d-10e546513bce",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "Este código configura y utiliza un flujo de datos (streaming) en Apache Spark para procesar datos en tiempo real, aplicando un modelo de machine learning a estos datos a medida que llegan. \n",
    "\n",
    "1. **Definición del esquema (`schema1`):** \n",
    "   - Se define un esquema llamado `schema1` utilizando `StructType`. Este esquema especifica las columnas, sus tipos de datos, y si pueden contener valores nulos (`True` indica que sí pueden ser nulos). \n",
    "\n",
    "2. **Creación de la fuente de datos para el stream (`streamingInputDF`):**\n",
    "   - Utiliza `spark.readStream` para leer datos en tiempo real con el formato `parquet` desde una ubicación especificada en DBFS (`\"dbfs:/FileStore/tables/proyecto/streaming/\"`), aplicando el esquema `schema1` definido previamente. Esto prepara los datos para ser procesados en streaming.\n",
    "\n",
    "3. **Aplicar el modelo al stream de datos (`streamingPredictions`):**\n",
    "   - Aplica un modelo de machine learning (`model`) al DataFrame de streaming (`streamingInputDF`). Esto implica que el modelo realizará predicciones o transformaciones en los datos en tiempo real a medida que llegan.\n",
    "\n",
    "4. **Visualizar el stream de datos resultante:**\n",
    "   - `display(streamingPredictions.limit(6))` muestra las primeras 6 filas del DataFrame resultante con las predicciones o transformaciones aplicadas. En el contexto de Databricks, `display` es una función que facilita la visualización de DataFrames y streams de datos.\n",
    "\n",
    "Este flujo de trabajo permite procesar y analizar datos en tiempo real utilizando Spark Structured Streaming, lo cual es ideal para escenarios donde es crucial obtener información instantánea o aplicar modelos de machine learning a datos que se actualizan constantemente, como en sistemas de recomendación, monitoreo en tiempo real, o análisis de satisfacción del cliente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61bd2615-32df-470f-b62e-d54ded48f6c9",
     "showTitle": true,
     "title": "Fase 4: Implementación de una Consulta adicional"
    }
   },
   "source": [
    "\n",
    "Se creará una segunda consulta (query) sobre el stream resultante del paso anterior a partir del método writeStream() con un modo de salida “append”, formato “memory” y nombre “encuestaClassification”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ef5eb93-047d-47f5-8843-c290a554a197",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = streamingPredictions.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName(\"encuestaClassification\") \\\n",
    "    .start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11c5756e-a596-4b24-86bd-dc461b273f96",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "La parte del código que has proporcionado se utiliza para iniciar un flujo de escritura (write stream) en Apache Spark, configurado para procesar y almacenar los resultados de las predicciones del modelo en memoria. Esto permite consultar y visualizar los resultados en tiempo real. Te detallo cada componente de esta operación:\n",
    "\n",
    "1. **`streamingPredictions.writeStream`:** Inicia la configuración de un flujo de escritura para el DataFrame `streamingPredictions`, que contiene las predicciones o transformaciones aplicadas a los datos de entrada en tiempo real.\n",
    "\n",
    "2. **`.outputMode(\"append\")`:** Configura el modo de salida del stream. El modo `\"append\"` significa que solo los nuevos registros (filas) resultantes de las predicciones se añadirán al resultado final. Esto es típico en situaciones donde los datos se van acumulando con el tiempo y no necesitas reescribir o actualizar registros existentes.\n",
    "\n",
    "3. **`.format(\"memory\")`:** Establece el formato de salida del stream a `\"memory\"`. Esto permite que los resultados del stream se almacenen en la memoria del cluster, lo cual es útil para pruebas, depuración, y visualización rápida de los datos procesados en tiempo real. \n",
    "\n",
    "4. **`.queryName(\"encuestaClassification\")`:** Asigna un nombre a la consulta del stream, en este caso, `\"encuestaClassification\"`. Este nombre se utiliza para referenciar y consultar los datos resultantes almacenados en memoria a través de SQL o API de DataFrame.\n",
    "\n",
    "5. **`.start()`:** Inicia la ejecución del flujo de escritura configurado. Una vez iniciado, Spark comenzará a procesar los datos de entrada en tiempo real, aplicará las transformaciones o predicciones del modelo y almacenará los resultados en memoria según la configuración especificada.\n",
    "\n",
    "Con este flujo, se pueden realizar consultas en tiempo real a los datos resultantes utilizando el nombre de la consulta `\"encuestaClassification\"` para analizar los datos procesados, realizar más transformaciones, o visualizar los resultados directamente en herramientas de Databricks o Spark SQL. Esta capacidad es especialmente valiosa para aplicaciones de análisis en tiempo real, donde la inmediatez de los datos procesados es crucial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e263dbd-26bf-4326-91ce-dfc1e06c37b4",
     "showTitle": true,
     "title": "Fase 5: Evaluación del Modelo en streaming"
    }
   },
   "source": [
    "\n",
    "Crear un objeto evaluador del tipo MulticlassClassificationEvaluator para obtener la métrica “accuracy”.\n",
    "\n",
    "A partir de la consulta “encuestaClassification” generar un Dataframe utilizando spark.sql() y pasar este Dataframe resultante como parámetro al evaluador utilizando el método evaluate(). \n",
    "\n",
    "Finalmente, imprimir la métrica de “accuracy” resultante para el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45bad0a5-6f25-4883-abb7-fb2ebfabb3de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8167827995072374\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Crear el evaluador\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"satisfaction_binary\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "# Usar spark.sql para seleccionar los datos de la consulta en memoria\n",
    "accuracyDF = spark.sql(\"SELECT satisfaction_binary, prediction FROM encuestaClassification\")\n",
    "\n",
    "# Evaluar la precisión\n",
    "accuracy = evaluator.evaluate(accuracyDF)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 999350958486406,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "ML para datos en Streaming",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
